<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Maryamâ€™s Free AI Chatbot</title>
  <style>
    body{font-family:system-ui,Arial,sans-serif;margin:0;background:#0b0b0c;color:#eee}
    .wrap{max-width:820px;margin:0 auto;padding:24px}
    h1{font-size:1.25rem;margin:0 0 12px}
    #log{background:#121214;border:1px solid #1e1e22;border-radius:12px;padding:16px;height:60vh;overflow:auto}
    .msg{margin:10px 0;line-height:1.45}
    .you{color:#c9f}
    .bot{color:#9fe29f;white-space:pre-wrap}
    form{display:flex;gap:8px;margin-top:12px}
    input,button{font:inherit}
    input{flex:1;padding:12px;border-radius:10px;border:1px solid #1e1e22;background:#121214;color:#eee}
    button{padding:12px 16px;border-radius:10px;border:0;background:#4b9cff;color:#fff;cursor:pointer}
    button:disabled{opacity:.6;cursor:not-allowed}
    .small{opacity:.75;font-size:.9rem;margin-top:6px}
  </style>
</head>
<body>
  <div class="wrap">
    <h1>ðŸ¤– Maryamâ€™s AI (runs in your browser)</h1>
    <div id="log"></div>
    <form id="chat">
      <input id="inp" placeholder="Type your messageâ€¦" autocomplete="off" />
      <button id="send">Send</button>
    </form>
    <div class="small">First load may take a bit while the small model downloads. Chrome/Edge recommended.</div>
  </div>

  <script type="module">
    // Uses WebLLM to run a tiny model locally (no API key needed)
    import * as webllm from "https://esm.run/@mlc-ai/web-llm";

    const log = document.getElementById('log');
    const inp = document.getElementById('inp');
    const btn = document.getElementById('send');
    const form = document.getElementById('chat');

    const MODEL = "Llama-3.2-1B-Instruct-q4f32_1-MLC"; // small = faster first load

    function add(role, text){
      const d=document.createElement('div');
      d.className='msg ' + (role==='user'?'you':'bot');
      d.textContent=(role==='user'?'You: ':'AI: ')+text;
      log.appendChild(d); log.scrollTop=log.scrollHeight;
    }

    // init engine once
    let engineReady = (async ()=>{
      return await webllm.CreateMLCEngine(MODEL, {
        initProgressCallback: p => console.log(p)
      });
    })();

    form.addEventListener('submit', async (e)=>{
      e.preventDefault();
      const q = inp.value.trim();
      if(!q) return;
      add('user', q);
      inp.value=''; inp.focus(); btn.disabled=true;

      const engine = await engineReady;

      const stream = await engine.chat.completions.create({
        messages: [
          { role: "system", content: "You are a friendly helpful assistant." },
          { role: "user", content: q }
        ],
        stream: true
      });

      let
